{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Review - Zero Shot - Error EDA\n",
    "\n",
    "This notebook is for the error analysis and eda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../../test_predictions.pkl'\n",
    "test_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../imdb_test_predictions.pkl'\n",
    "imdb_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../twitter_sent140_test_predictions.pkl'\n",
    "twitter_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../yelp_test_predictions.pkl'\n",
    "yelp_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../yelp_zhang_test_predictions.pkl'\n",
    "yelp_zhang_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../amazon_zhang_test_predictions.pkl'\n",
    "amazon_zhang_results = pd.read_pickle(file_name)\n",
    "\n",
    "file_name = '../../sst_test_predictions.pkl'\n",
    "sst_results = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendPreds(data):\n",
    "    cols = ['USE_Soft', 'CNN_TE', 'CNN_TE_USE', 'CNN_Glove', 'CNN_Glove_USE',\n",
    "        'CNN_w2V', 'CNN_w2V_USE', 'Individual_Sent', 'Average_Sent']\n",
    "    preds = ['USE_Soft_pred', 'CNN_TE_pred', 'CNN_TE_USE_pred', 'CNN_Glove_pred', 'CNN_Glove_USE_pred',\n",
    "        'CNN_w2V_pred', 'CNN_w2V_USE_pred', 'Individual_Sent_pred', 'Average_Sent_pred']\n",
    "    \n",
    "    for col, pred in zip(cols,preds):\n",
    "        data[pred] = np.where(data[col]>=0.5,1,0)\n",
    "        \n",
    "    return data\n",
    "\n",
    "test_results = appendPreds(test_results)\n",
    "\n",
    "imdb_results = appendPreds(imdb_results)\n",
    "\n",
    "twitter_results = appendPreds(twitter_results)\n",
    "\n",
    "yelp_results = appendPreds(yelp_results)\n",
    "\n",
    "yelp_zhang_results = appendPreds(yelp_zhang_results)\n",
    "\n",
    "amazon_zhang_results = appendPreds(amazon_zhang_results)\n",
    "\n",
    "sst_results = appendPreds(sst_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDifs(data, cutoff = 2, Indv = True, Avg = True):\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    newDF = data\n",
    "    preds = ['USE_Soft_pred', 'CNN_TE_pred', 'CNN_TE_USE_pred', 'CNN_Glove_pred', 'CNN_Glove_USE_pred',\n",
    "        'CNN_w2V_pred', 'CNN_w2V_USE_pred']\n",
    "    \n",
    "    indiv = ['Individual_Sent_pred']\n",
    "    avg = ['Average_Sent_pred']\n",
    "    \n",
    "    USE = [True, False, True, False, True, False, True, True, True]\n",
    "    \n",
    "    newDF['Preds_Agree3'] = np.where((newDF['CNN_TE_pred']==newDF['CNN_Glove_pred'])\n",
    "                                    & (newDF['CNN_Glove_pred']==newDF['CNN_w2V_pred']),1,0)\n",
    "    newDF['Preds_Agree2'] = np.where((newDF['CNN_TE_pred']==newDF['CNN_Glove_pred'])\n",
    "                                    | (newDF['CNN_Glove_pred']==newDF['CNN_w2V_pred'])\n",
    "                                    | (newDF['CNN_TE_pred']==newDF['CNN_w2V_pred']),1,0)\n",
    "    \n",
    "    newDF['USE_Preds_Agree3'] = np.where((newDF['CNN_TE_USE_pred']==newDF['CNN_Glove_USE_pred'])\n",
    "                                    & (newDF['CNN_Glove_USE_pred']==newDF['CNN_w2V_USE_pred']),1,0)\n",
    "    newDF['USE_Preds_Agree2'] = np.where((newDF['CNN_TE_USE_pred']==newDF['CNN_Glove_USE_pred'])\n",
    "                                    | (newDF['CNN_Glove_USE_pred']==newDF['CNN_w2V_USE_pred'])\n",
    "                                    | (newDF['CNN_TE_USE_pred']==newDF['CNN_w2V_USE_pred']),1,0)\n",
    "    \n",
    "    newDF['dis_3'] = np.where((newDF['Preds_Agree3']==newDF['USE_Preds_Agree3'])\n",
    "                                    & (((newDF['CNN_Glove_USE_pred']!=newDF['sentiment']) & \n",
    "                                      (newDF['CNN_Glove_pred']==newDF['sentiment'])) |\n",
    "                                    ((newDF['CNN_Glove_USE_pred']==newDF['sentiment']) & \n",
    "                                      (newDF['CNN_Glove_pred']!=newDF['sentiment']))),1,0)\n",
    "    return n, newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, test_results = checkDifs(test_results)\n",
    "USE_imp_test = test_results.loc[(test_results['USE_Preds_Agree3'] == 1) & (test_results['Preds_Agree3'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_imp_test = USE_imp_test.drop(['Average_Sent_pred','Individual_Sent_pred','Preds_Agree2','USE_Preds_Agree2',], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_use = USE_imp_test.loc[((USE_imp_test['dis_3'] == 1) & (USE_imp_test['CNN_TE_USE_pred'] == USE_imp_test['sentiment']))]\n",
    "count_norm = USE_imp_test.loc[((USE_imp_test['dis_3'] == 1) & (USE_imp_test['CNN_TE_pred'] == USE_imp_test['sentiment']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_use = count_use.shape[0]\n",
    "n_norm = count_norm.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest Sentence Where USE + embeddings correct\n",
    "\n",
    "Looking at the data, below. The models that included the universal sentence encoder seems to have captured sentiment better (unanimously) than the model without the sentence encoder. This could be because of a number of reasons. For one, the inclusion of stop words likely affects how the CNN interprets this review, especially because the review clearly changes sentiment throughout. In either case, it is interesting that the inclusion of the embeddings from the USE allowed the model to tease out that this was a positive sentiment when the regular CNNs (with only word level embeddings) were unable to get this one correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0\n",
      "[['five', 'stars', 'me', 'for', 'a', 'book', 'written', 'by', 'and', 'for', 'men', 'me', 'the', 'feminist', 'yep', 'yep', 'and', 'yep', 'and', 'there', 'was', 'need', 'for', 'better', 'editing', 'still', 'five', 'whole', 'stars', 'this', 'book', 'addresses', 'what', 'i', 'fight', 'for', 'equality', 'i', 'have', 'spent', 'my', 'last', 'few', 'month', 'making', 'gifts', 'either', 'crocheting', 'or', 'knitting', 'lots', 'of', 'websites', 'and', 'ebooks', 'came', 'and', 'blurred', 'before', 'my', 'eyes', 'most', 'of', 'the', 'books', 'assume', 'you', 'are', 'a', 'woman', 'a', 'house', 'wifely', 'type', 'with', 'no', 'real', 'men', 'in', 'your', 'life', 'to', 'make', 'things', 'for', 'they', 'are', 'all', 'dedicated', 'to', 'girly', 'girls', 'with', 'squishy', 'babies', 'hey', 'been', 'there', 'done', 'that', 'with', 'four', 'full', 'grown', 'off', 'spring', 'three', 'males', 'one', 'female', 'to', 'prove', 'it', 'this', 'book', 'will', 'not', 'be', 'wiped', 'off', 'my', 'kindle', 'or', 'tablet', 'or', 'kindle', 'pc', 'as', 'i', 'plan', 'to', 'dip', 'into', 'it', 'often', 'not', 'only', 'are', 'there', 'patterns', 'for', 'skull', 'hats', 'arm', 'braces', 'mice', 'dragons', 'and', 'blood', 'shot', 'eyeballs', 'there', 'are', 'purses', 'and', 'trinkets', 'for', 'mom', 'or', 'sister', 'or', 'dare', 'i', 'say', 'it', 'girlfriends', 'wives', 'and', 'these', 'guys', 'have', 'proven', 'that', 'they', 'can', 'fly', 'pattern', 'free', 'with', 'a', 'little', 'math', 'is', 'that', 'cool', 'or', 'what', 'and', 'they', 'show', 'how', 'to', 'knit', 'needle', 'free', 'there', 'are', 'lots', 'of', 'pictures']]\n",
      "\n",
      "_________________\n",
      "\n",
      "[\"Five stars? Me? For a book written by and for MEN? Me, the feminist? YEP, yep and yep. And there was need for better editing! Still FIVE whole stars! This book addresses what I fight for. Equality. I have spent my last few month making gifts either crocheting or knitting. Lots of websites and ebooks came and blurred before my eyes. Most of the books assume you are a woman, a house-wifely-type, with no real men in your life to make things for. They are all dedicated to girly girls with squishy babies. Hey, been there done that with four full grown off-spring, three males, one female, to prove it.This book will not be wiped off my Kindle or Tablet or Kindle PC as I plan to dip into it often. Not only are there patterns for skull hats, arm braces, mice, dragons and blood-shot eyeballs, there are purses, and trinkets for mom or sister, or dare I say it? Girlfriends/wives. And these guys have proven that they can fly pattern free with a little math! Is that cool or what? And they show how to knit needle free! There are lots of pictures and explanations for those of us that need more, and it is offered with a good sense of humor!I loved this book! And I didn't read all of it, my eyes started blurring after a page or two of K1, P2, K1 etc. But I do know that when I decide to make something from the book the instructions are right there waiting for me! Thanks, guys!\"]\n"
     ]
    }
   ],
   "source": [
    "check_lens = [len(words) for words in count_use['sentenceWords']]\n",
    "\n",
    "med_use = np.median(check_lens)\n",
    "print(med_use)\n",
    "print(list(count_use['sentenceWords'][:200].iloc[[np.argmax(check_lens)]]))\n",
    "print('\\n_________________\\n')\n",
    "print(list(count_use['reviewText'].iloc[[np.argmax(check_lens)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Glove_USE_pred\n",
      "Accuracy: 0.9481791666666667\n",
      "Precision: 0.9532747300907705\n",
      "Recall: 0.9425583333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114456</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6893</td>\n",
       "      <td>113107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted              0       1\n",
       "Actual Sentiment                \n",
       "0                 114456    5544\n",
       "1                   6893  113107"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createConfusion(data, model):\n",
    "    \n",
    "    y_actu = pd.Series(data['sentiment'], name='Actual Sentiment')\n",
    "    y_pred = pd.Series(data[model], name='Predicted')\n",
    "    \n",
    "    conf = pd.crosstab(y_actu, y_pred)\n",
    "    \n",
    "    true_pos = np.diag(conf) \n",
    "    print(model)\n",
    "    print('Accuracy: {}'.format(np.sum(true_pos)/data.shape[0]))\n",
    "    \n",
    "    precision = np.sum(true_pos[1] / np.sum(conf[1], axis=0))\n",
    "    recall = np.sum(true_pos[1] / np.sum(conf.iloc[1]))\n",
    "    \n",
    "    print('Precision: {}'.format(precision))\n",
    "    print('Recall: {}'.format(recall))\n",
    "\n",
    "    return conf\n",
    "\n",
    "\n",
    "df_confusion_CNN_G = createConfusion(test_results,'CNN_Glove_USE_pred')\n",
    "df_confusion_CNN_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Glove_pred\n",
      "Accuracy: 0.9338166666666666\n",
      "Precision: 0.9616380533484676\n",
      "Recall: 0.9036833333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115674</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11558</td>\n",
       "      <td>108442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted              0       1\n",
       "Actual Sentiment                \n",
       "0                 115674    4326\n",
       "1                  11558  108442"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_CNN_G = createConfusion(test_results,'CNN_Glove_pred')\n",
    "df_confusion_CNN_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Glove_USE_pred\n",
      "Accuracy: 0.86076\n",
      "Precision: 0.8890518505737209\n",
      "Recall: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11214</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2195</td>\n",
       "      <td>10305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             0      1\n",
       "Actual Sentiment              \n",
       "0                 11214   1286\n",
       "1                  2195  10305"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_CNN_G = createConfusion(imdb_results,'CNN_Glove_USE_pred')\n",
    "df_confusion_CNN_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Glove_pred\n",
      "Accuracy: 0.82912\n",
      "Precision: 0.9092717867091126\n",
      "Recall: 0.7312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11588</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3360</td>\n",
       "      <td>9140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted             0     1\n",
       "Actual Sentiment             \n",
       "0                 11588   912\n",
       "1                  3360  9140"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_CNN_G = createConfusion(imdb_results,'CNN_Glove_pred')\n",
    "df_confusion_CNN_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
