{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Final Project - Amazon Reviews\n",
    "\n",
    "This notebook is to read in the cleaned data and work with the data in keras.\n",
    "\n",
    "http://jmcauley.ucsd.edu/data/amazon/links.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:07:18.419154Z",
     "start_time": "2019-03-21T20:07:18.415783Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lance_miles/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0328 01:11:14.086686 140345287345984 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T17:11:55.894807Z",
     "start_time": "2019-03-21T17:11:13.582094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lance_miles/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = ['reviews_Video_Games.json.gz', \n",
    "         'reviews_Toys_and_Games.json.gz', \n",
    "         'reviews_Sports_and_Outdoors.json.gz', \n",
    "         'reviews_Movies_and_TV.json.gz',\n",
    "         'reviews_Kindle_Store.json.gz', \n",
    "         'reviews_Home_and_Kitchen.json.gz',\n",
    "         'reviews_Health_and_Personal_Care.json.gz', \n",
    "         'reviews_Electronics.json.gz',\n",
    "         'reviews_Clothing_Shoes_and_Jewelry.json.gz',\n",
    "         'reviews_Cell_Phones_and_Accessories.json.gz', \n",
    "         'reviews_CDs_and_Vinyl.json.gz',\n",
    "         'reviews_Books.json.gz']\n",
    "filesNames = ['reviews_Video_Games', \n",
    "              'reviews_Toys_and_Games',\n",
    "              'reviews_Sports_and_Outdoors', \n",
    "              'reviews_Movies_and_TV',\n",
    "              'reviews_Kindle_Store', \n",
    "              'reviews_Home_and_Kitchen',\n",
    "              'reviews_Health_and_Personal_Care', \n",
    "              'reviews_Electronics',\n",
    "              'reviews_Clothing_Shoes_and_Jewelry',\n",
    "              'reviews_Cell_Phones_and_Accessories', \n",
    "              'reviews_CDs_and_Vinyl',\n",
    "              'reviews_Books']\n",
    "\n",
    "def dataFullSets(original, concatData, name):\n",
    "    currentData = original\n",
    "    appendData = pd.read_csv('../Data/%s'%(concatData))\n",
    "    appendData['Product'] = name\n",
    "    newDF = pd.concat([currentData,appendData])\n",
    "    return(newDF)\n",
    "\n",
    "train_data = pd.read_csv('../Data/%s_train.csv'%(filesNames[0]))\n",
    "train_data['Product'] = filesNames[0]\n",
    "test_data = pd.read_csv('../Data/%s_test.csv'%(filesNames[0]))\n",
    "test_data['Product'] = filesNames[0]\n",
    "\n",
    "random.seed(1203)\n",
    "\n",
    "for fileName in filesNames[1:]:\n",
    "    concatName_train = str(fileName+'_train.csv')\n",
    "    concatName_test = fileName+'_test.csv'\n",
    "                        \n",
    "    train_data = dataFullSets(train_data, concatName_train, fileName).sample(frac=1)\n",
    "    test_data = dataFullSets(test_data, concatName_test, fileName).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T17:11:55.945562Z",
     "start_time": "2019-03-21T17:11:55.896787Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60727</th>\n",
       "      <td>reviews_Health_and_Personal_Care</td>\n",
       "      <td>B001ECQ72S</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazon offers the pack of 3 for the same price...</td>\n",
       "      <td>09 4, 2011</td>\n",
       "      <td>A3RL90G39VP7DD</td>\n",
       "      <td>Jessica R. Richards \"Miss Jess\"</td>\n",
       "      <td>1</td>\n",
       "      <td>CANNOT BEAT THE PRICE</td>\n",
       "      <td>1315094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65842</th>\n",
       "      <td>reviews_Toys_and_Games</td>\n",
       "      <td>B000GFJAZU</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The boat is great.  Loved the propeller drive ...</td>\n",
       "      <td>02 4, 2012</td>\n",
       "      <td>A20WXI56F4VJI0</td>\n",
       "      <td>western</td>\n",
       "      <td>0</td>\n",
       "      <td>propeller</td>\n",
       "      <td>1328313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75259</th>\n",
       "      <td>reviews_Movies_and_TV</td>\n",
       "      <td>630150528X</td>\n",
       "      <td>[3, 16]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We received the DVD in a timely manner, but wh...</td>\n",
       "      <td>04 2, 2009</td>\n",
       "      <td>A1GGZ0MK5L95QV</td>\n",
       "      <td>A. Degregorio</td>\n",
       "      <td>0</td>\n",
       "      <td>The African Queen</td>\n",
       "      <td>1238630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90632</th>\n",
       "      <td>reviews_Electronics</td>\n",
       "      <td>B003DZ1652</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really just what I  wanted and works very nice...</td>\n",
       "      <td>10 6, 2010</td>\n",
       "      <td>AUKTNR0B28DFU</td>\n",
       "      <td>W. S. Johnston \"Wanlyn\"</td>\n",
       "      <td>1</td>\n",
       "      <td>KINDLE BOOK COVER</td>\n",
       "      <td>1286323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63590</th>\n",
       "      <td>reviews_Movies_and_TV</td>\n",
       "      <td>B002VECLVO</td>\n",
       "      <td>[9, 75]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is possible the worst movie that I have s...</td>\n",
       "      <td>09 27, 2010</td>\n",
       "      <td>A2VBGC203PW4U8</td>\n",
       "      <td>E. Stanford \"beach belle\"</td>\n",
       "      <td>0</td>\n",
       "      <td>stay away</td>\n",
       "      <td>1285545600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Product        asin  helpful  overall  \\\n",
       "60727  reviews_Health_and_Personal_Care  B001ECQ72S   [0, 0]      5.0   \n",
       "65842            reviews_Toys_and_Games  B000GFJAZU   [0, 1]      1.0   \n",
       "75259             reviews_Movies_and_TV  630150528X  [3, 16]      1.0   \n",
       "90632               reviews_Electronics  B003DZ1652   [0, 0]      5.0   \n",
       "63590             reviews_Movies_and_TV  B002VECLVO  [9, 75]      1.0   \n",
       "\n",
       "                                              reviewText   reviewTime  \\\n",
       "60727  Amazon offers the pack of 3 for the same price...   09 4, 2011   \n",
       "65842  The boat is great.  Loved the propeller drive ...   02 4, 2012   \n",
       "75259  We received the DVD in a timely manner, but wh...   04 2, 2009   \n",
       "90632  Really just what I  wanted and works very nice...   10 6, 2010   \n",
       "63590  This is possible the worst movie that I have s...  09 27, 2010   \n",
       "\n",
       "           reviewerID                     reviewerName  sentiment  \\\n",
       "60727  A3RL90G39VP7DD  Jessica R. Richards \"Miss Jess\"          1   \n",
       "65842  A20WXI56F4VJI0                          western          0   \n",
       "75259  A1GGZ0MK5L95QV                    A. Degregorio          0   \n",
       "90632   AUKTNR0B28DFU          W. S. Johnston \"Wanlyn\"          1   \n",
       "63590  A2VBGC203PW4U8        E. Stanford \"beach belle\"          0   \n",
       "\n",
       "                     summary  unixReviewTime  \n",
       "60727  CANNOT BEAT THE PRICE      1315094400  \n",
       "65842              propeller      1328313600  \n",
       "75259      The African Queen      1238630400  \n",
       "90632      KINDLE BOOK COVER      1286323200  \n",
       "63590              stay away      1285545600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T17:11:55.993872Z",
     "start_time": "2019-03-21T17:11:55.948370Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15945</th>\n",
       "      <td>reviews_Toys_and_Games</td>\n",
       "      <td>B000H6DWSY</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The suction cups are not big enough to hold up...</td>\n",
       "      <td>06 16, 2007</td>\n",
       "      <td>A1P67VA81DMVKN</td>\n",
       "      <td>KCBlueGal</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't even waste your money</td>\n",
       "      <td>1181952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>reviews_Electronics</td>\n",
       "      <td>B002NKNWAA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Was not the right battery ... Pic that was on ...</td>\n",
       "      <td>10 22, 2013</td>\n",
       "      <td>A25WAQ4PLMA9EM</td>\n",
       "      <td>k9</td>\n",
       "      <td>0</td>\n",
       "      <td>why me</td>\n",
       "      <td>1382400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>reviews_Kindle_Store</td>\n",
       "      <td>B00BG52E7U</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>In the waning years of the Weimar Republic, Se...</td>\n",
       "      <td>06 22, 2014</td>\n",
       "      <td>A1BM2S6I7QTCOF</td>\n",
       "      <td>Wolfgang Manowski</td>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Nazi Propaganda Effort</td>\n",
       "      <td>1403395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>reviews_Books</td>\n",
       "      <td>B00DYV8NKQ</td>\n",
       "      <td>[8, 11]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I purchased this because I enjoyed Hugh 's Sil...</td>\n",
       "      <td>08 24, 2013</td>\n",
       "      <td>A1IS7P2WM8ASFP</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>0</td>\n",
       "      <td>Not the same as Hugh</td>\n",
       "      <td>1377302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>reviews_Health_and_Personal_Care</td>\n",
       "      <td>B000F8KAKC</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In the description of this product, it says th...</td>\n",
       "      <td>11 20, 2007</td>\n",
       "      <td>A31ZCAL11QQPI</td>\n",
       "      <td>Dr. C.</td>\n",
       "      <td>0</td>\n",
       "      <td>Wrong!!</td>\n",
       "      <td>1195516800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Product        asin  helpful  overall  \\\n",
       "15945            reviews_Toys_and_Games  B000H6DWSY   [1, 1]      1.0   \n",
       "4837                reviews_Electronics  B002NKNWAA   [0, 0]      1.0   \n",
       "6504               reviews_Kindle_Store  B00BG52E7U   [0, 0]      5.0   \n",
       "15937                     reviews_Books  B00DYV8NKQ  [8, 11]      1.0   \n",
       "5978   reviews_Health_and_Personal_Care  B000F8KAKC   [0, 0]      1.0   \n",
       "\n",
       "                                              reviewText   reviewTime  \\\n",
       "15945  The suction cups are not big enough to hold up...  06 16, 2007   \n",
       "4837   Was not the right battery ... Pic that was on ...  10 22, 2013   \n",
       "6504   In the waning years of the Weimar Republic, Se...  06 22, 2014   \n",
       "15937  I purchased this because I enjoyed Hugh 's Sil...  08 24, 2013   \n",
       "5978   In the description of this product, it says th...  11 20, 2007   \n",
       "\n",
       "           reviewerID       reviewerName  sentiment  \\\n",
       "15945  A1P67VA81DMVKN          KCBlueGal          0   \n",
       "4837   A25WAQ4PLMA9EM                 k9          0   \n",
       "6504   A1BM2S6I7QTCOF  Wolfgang Manowski          1   \n",
       "15937  A1IS7P2WM8ASFP    Amazon Customer          0   \n",
       "5978    A31ZCAL11QQPI             Dr. C.          0   \n",
       "\n",
       "                           summary  unixReviewTime  \n",
       "15945  Don't even waste your money      1181952000  \n",
       "4837                        why me      1382400000  \n",
       "6504   Anti-Nazi Propaganda Effort      1403395200  \n",
       "15937         Not the same as Hugh      1377302400  \n",
       "5978                       Wrong!!      1195516800  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I bought this the end of December (2013). I dieted for a month got on the scale and it showed I had lost 10lbs. I weighed myself two weeks later and it showed I had lost 13 lbs. If you want to &#34;believe&#34; you lost weight while eating as much if not more than you normally do this scale is for you!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#practice sentence\n",
    "test_sentence = test_data['reviewText'].iloc[19]\n",
    "test_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i bought this the end of december         i dieted for a month got on the scale and it showed i had lost   lbs  i weighed myself two weeks later and it showed i had lost    lbs  if you want to      believe      you lost weight while eating as much if not more than you normally do this scale is for you '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare reviews to be split by words\n",
    "#change to lowercase, remove punctuation and numbers\n",
    "test_data_word_prep = re.sub(\"[^a-zA-Z]\", \" \", test_sentence).lower()\n",
    "test_data_word_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'bought',\n",
       " 'this',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'december',\n",
       " 'i',\n",
       " 'dieted',\n",
       " 'for',\n",
       " 'a',\n",
       " 'month',\n",
       " 'got',\n",
       " 'on',\n",
       " 'the',\n",
       " 'scale',\n",
       " 'and',\n",
       " 'it',\n",
       " 'showed',\n",
       " 'i',\n",
       " 'had',\n",
       " 'lost',\n",
       " 'lbs',\n",
       " 'i',\n",
       " 'weighed',\n",
       " 'myself',\n",
       " 'two',\n",
       " 'weeks',\n",
       " 'later',\n",
       " 'and',\n",
       " 'it',\n",
       " 'showed',\n",
       " 'i',\n",
       " 'had',\n",
       " 'lost',\n",
       " 'lbs',\n",
       " 'if',\n",
       " 'you',\n",
       " 'want',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'you',\n",
       " 'lost',\n",
       " 'weight',\n",
       " 'while',\n",
       " 'eating',\n",
       " 'as',\n",
       " 'much',\n",
       " 'if',\n",
       " 'not',\n",
       " 'more',\n",
       " 'than',\n",
       " 'you',\n",
       " 'normally',\n",
       " 'do',\n",
       " 'this',\n",
       " 'scale',\n",
       " 'is',\n",
       " 'for',\n",
       " 'you']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of words after processing\n",
    "test_data_word_prep.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i bought this the end of december       . i dieted for a month got on the scale and it showed i had lost   lbs. i weighed myself two weeks later and it showed i had lost    lbs. if you want to      believe      you lost weight while eating as much if not more than you normally do this scale is for you.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare reviews to be split by sentences\n",
    "#change to lowercase, changes (!?) to (.), removes numbers, allows to be split by periods\n",
    "test_data_sent_prep = re.sub(\"[!?]\", \".\", test_sentence)\n",
    "test_data_sent_prep = re.sub(\"[^a-zA-Z.]\", \" \", test_data_sent_prep).lower()\n",
    "test_data_sent_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i bought this the end of december',\n",
       " 'i dieted for a month got on the scale and it showed i had lost   lbs',\n",
       " 'i weighed myself two weeks later and it showed i had lost    lbs',\n",
       " 'if you want to      believe      you lost weight while eating as much if not more than you normally do this scale is for you',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of sentences after processing\n",
    "[sent.strip(\" \") for sent in test_data_sent_prep.split('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:04:03.921115Z",
     "start_time": "2019-03-21T20:03:10.378683Z"
    }
   },
   "outputs": [],
   "source": [
    "play_data = test_data[:10]\n",
    "#print(play_data)\n",
    "\n",
    "#function to process review text and split into words\n",
    "def splitWords(data):\n",
    "    data_prep = str(data['reviewText'])\n",
    "    data_prep = re.sub(\"[^a-zA-Z]\", \" \", data_prep).lower()\n",
    "    return data_prep.split()\n",
    "\n",
    "#function to process review text and split into sentences\n",
    "def splitSentences(data):\n",
    "    data_prep = str(data['reviewText'])\n",
    "    data_prep = re.sub(\"[!?]\", \".\", data_prep)\n",
    "    data_prep = re.sub(\"[^a-zA-Z.]\", \" \", data_prep).lower().split('.')\n",
    "    data_prep = [sentence.strip(\" \") for sentence in data_prep]\n",
    "    return data_prep\n",
    "\n",
    "\n",
    "#list of words from review into column\n",
    "sentences = play_data.apply(splitWords, axis=1)\n",
    "play_data.insert(loc = 11, column = 'sentenceWords', value = sentences)\n",
    "\n",
    "sentences = train_data.apply(splitWords, axis=1)\n",
    "train_data.insert(loc = 11,column = 'sentenceWords', value = sentences)\n",
    "\n",
    "sentences = test_data.apply(splitWords, axis=1)\n",
    "test_data.insert(loc = 11,column = 'sentenceWords', value = sentences)\n",
    "\n",
    "\n",
    "#list of sentences from review into column\n",
    "sentences_split = play_data.apply(splitSentences, axis=1)\n",
    "play_data.insert(loc = 12, column = 'sentences', value = sentences_split)\n",
    "\n",
    "sentences_split = train_data.apply(splitSentences, axis=1)\n",
    "train_data.insert(loc = 12,column = 'sentences', value = sentences_split)\n",
    "\n",
    "sentences_split = test_data.apply(splitSentences, axis=1)\n",
    "test_data.insert(loc = 12,column = 'sentences', value = sentences_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:04:30.500814Z",
     "start_time": "2019-03-21T20:04:03.931150Z"
    }
   },
   "outputs": [],
   "source": [
    "wordFreq = defaultdict(int)\n",
    "\n",
    "wordData = train_data['sentenceWords']\n",
    "\n",
    "for row in wordData:\n",
    "    for word in row:\n",
    "        wordFreq[word] += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:08:13.992684Z",
     "start_time": "2019-03-21T20:08:13.948360Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wordsForHist = list(wordFreq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:08:17.320811Z",
     "start_time": "2019-03-21T20:08:16.613431Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lance_miles/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Word Frequency for Train Data')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(wordsForHist, bins=100, color = 'red').set_title('Word Frequency for Train Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:13:27.638555Z",
     "start_time": "2019-03-21T20:13:27.284719Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewLength = []\n",
    "\n",
    "for row in wordData:\n",
    "    reviewLength.append(len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T20:14:20.733542Z",
     "start_time": "2019-03-21T20:14:20.198952Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lance_miles/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Sentence Lengths for Train Data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(reviewLength, bins=100, color = 'red').set_title('Sentence Lengths for Train Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 81.19317833333334\n",
      "Median: 47.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',np.mean(reviewLength))\n",
    "print('Median:',np.median(reviewLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The suction cups are not big enough to hold up this fairly heavy toy. The toy stayed on the wall, albeit a bit wobbly, until I pumped the toy full of water. *PLOP* right into the tub. After that, it wouldn\\'t stay on the wall because I couldn\\'t get the suction cups nor the wall dry enough for it to mount, and it kept sliding right into the bath water.The other reviewers were correct in stating that the first time, you have to pump this toy about 15 times to get the toy full of water, and then it only squirts out measly teaspoons of water at a time.I can easily believe that children under four years old will have a difficult time pushing the button hard enough to get the water to squirt, as other reviewers have mentioned. I can only imagine the resulting consequences if a younger child pushed so hard, she or he lost her seated balance in the tub, and went face-first into the water, or smashed his/her head on the bathtub wall or faucet.  Yet, the product dangerously markets itself to children as young as three years old.The package states \"makes washing hair easier\", which I believe to be an outright lie -- first being that I can\\'t even get the product to stay on the wall, and secondly is the fact that not enough water would be produced to soak any hair, much less provide enough for rinsing purposes.Since the product stated \"fun for all ages!\", I bought this for my 7-year old, who still enjoys a bath a couple of times a week (even though she transitioned successfully to showers three years ago) as a toy. The hose is stored in its packaging bent in to a \"U\" shape, and holds that shape outside of the package, making it difficult for me to mount the product low enough to reach the bath water, yet high enough to clear my daughter\\'s head.The product is not fun -- not for the child who will be disappointed when the toy won\\'t stay on the wall, and definitely not for me, who was soaking wet well after the bath water went cold while I tried unsuccessfully to mount this toy to the wall in any way I could. If I could give this product 0 stars, I would do so honestly and gladly.All in all, I spent about [...] for this (on sale at a discount department store), and the cardboard packaging this product was stored in is far more durable than the product itself.',\n",
       " \"Was not the right battery ... Pic that was on amazon was the correct battery but I got a total different one .. Not real happy and don't have that patience rright now to send back...\",\n",
       " 'In the waning years of the Weimar Republic, Sergei Stepanowitsch Tschachotin a Russian psychologist--trained as a microbiologist--and Carlo Mierendorff, a Socialdemocratic Reichstag deputy, tried to organize a counter movement to the massive Nazi demonstrations happening all over Germany. Dr. Richard Albrecht is the only author who has mastered this subject. Unfortunately, the &#34;Dreifeil&#34; effort failed and unfortunately, this book is only available in German.',\n",
       " \"I purchased this because I enjoyed Hugh 's Silo Saga and it had some glowing reviews. Unfortunately, I could not even make it through half the book before losing interest. This author is not only a poor editor but also a poor story teller.The head of IT was constantly lost in his own rambling thoughts and memories, which was annoying at best. At worst, it side tracks the reader and is a very poor method of character development the way it was used. I also noticed there were a lot of discrepancies compared to the original Silo world; it made me wonder whether this author was paying attention while reading Hugh 's series. Lastly, I could not help feeling that this author may have been searching for synonyms while writing, replacing words here and there. The descriptions and vocabulary seem forced at times. At others, it is glaringly amateur and crude; like the author just could not find a more elegant way to write it.\",\n",
       " 'In the description of this product, it says that it has 14 mg of Zinc Acetate, which is good, because it IS the cure for the common cold (this is how the title for the patent for zinc acetate lozenges is listed with the patent office).  But when I received my boxes, I found that these actually contain Zinc Gluconate, which gives you 30% of the effect of Zinc Acetate.  I considered sending these back, but realized it really wasn\\'t worth the effort.  Don\\'t buy this if you truly want \"The Cure For The Common Cold.\"',\n",
       " 'These earrings are for children. Looks NOTHING like the picture.  Picture deceiving. Way too small and thin for the money.',\n",
       " 'Non functional when I received it. Had to go to my local Game Stop and pay 2x the price for a functional charger. I guess you take a gamble when purchasing used gaming equipment so, it was not that big of a loss.',\n",
       " \"Nothing else needed to say but it's Little Big Town !!  Tornado rocks !!  Only thing missing is the video to it.\",\n",
       " \"I rated the joy a five, I have used other massages and this one fits and feels comfortable.You will have to warm it up like many of the other reviewers stated just under warm water.I haven't used the larger side yet just getting use to the smaller end. It looks like a piece ofArt. I also use it to massage the back of my shoulder it works both ways. If you purchase thisYou won't be disappointed. I haven't hit that spot yet, however I believe it shouldn't take longTo discover it.\",\n",
       " \"With all the great reviews previously written for this album, Lara Fabian's '9' doesn't really need another raving review. But I thought I should write this especially for fans out there who don't speak french but love Lara Fabian's music.Without a clue of what Miss Fabian is actually singing, I've bought this french CD album simply because I found myself totally captivated by her other song - 'Love By Grace'(from her first english album- released 2000). And, without any understanding, I've played '9' over and over again.....Why? Lara Fabian sings beautifully and the songs are work of art.No french is required to'fall for'this album. Love is BLIND, right?\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_par = [str(sent) for sent in (play_data['reviewText'])]\n",
    "test_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#supress messages\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    review_embeddings = sess.run(embedding((test_par)))\n",
    "    \n",
    "review_embeddings = np.array(review_embeddings)\n",
    "review_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#review_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "### TO DO:\n",
    "\n",
    "**Model Efforts**\n",
    "* Initialize and access word2vec embeddings in CNN\n",
    "* Initialize and access glove embeddings in CNN\n",
    "* Index Universal Sentence Embeddings for concatenation in CNN\n",
    "\n",
    "**Text Processing**\n",
    "* Contractions\n",
    "* Review Length (some as large as 6000?!)\n",
    "* Stopwords\n",
    "\n",
    "### Baseline Models\n",
    "#### CNN\n",
    "* Trained Embeddings\n",
    "* Word2Vec\n",
    "* Glove\n",
    "\n",
    "#### Softmax\n",
    "* Universal Sentence Encoder (USE)\n",
    "\n",
    "### Models to Test\n",
    "#### CNN (Concatentation)\n",
    "* Trained Embeddings + USE\n",
    "* Word2Vec + USE\n",
    "* Glove + USE\n",
    "\n",
    "**If extra time**\n",
    "* Zero shot learning - IMDB Reviews\n",
    "* Sentiment embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen       = 300   # max number of words in a comment to use \n",
    "\n",
    "list_sentences_train = list(play_data['reviewText'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen=maxlen, padding='post')\n",
    "\n",
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_labels = np.array(play_data['sentiment'])\n",
    "X_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_words_play = list(play_data['sentenceWords'])\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/umbertogriffo/cnn-yoon-kim-s-model-and-google-s-word2vec-model\n",
    "#https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../../GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "embedDim=300\n",
    "vocabulary_size=len(word_index)+1\n",
    "embedding_matrix_w2v = np.zeros((vocabulary_size, embedDim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix_w2v[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix_w2v[i]=np.random.normal(0,np.sqrt(0.25),embedDim)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.08007812,  0.10498047,  0.04980469, ...,  0.00366211,\n",
       "         0.04760742, -0.06884766],\n",
       "       [-0.17394402,  0.13729602, -0.30038901, ..., -0.41991443,\n",
       "         0.08470176,  0.49692143],\n",
       "       ...,\n",
       "       [ 0.22753906,  0.12011719,  0.06835938, ..., -0.12988281,\n",
       "         0.05151367, -0.03088379],\n",
       "       [ 0.203125  , -0.12304688, -0.02966309, ..., -0.0859375 ,\n",
       "         0.13378906,  0.02062988],\n",
       "       [-0.07373047,  0.06030273,  0.10791016, ..., -0.16796875,\n",
       "        -0.21972656, -0.00239563]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/umbertogriffo/cnn-yoon-kim-s-model-and-google-s-word2vec-model\n",
    "#https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights\n",
    "\n",
    "# embeddings_index = dict()\n",
    "# f = open('../../glove.840B.300d.txt')\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = ''.join(values[:-300])\n",
    "#     coefs = np.asarray(values[-300:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# embedding_matrix_glove = np.zeros((vocabulary_size, embedDim))\n",
    "# for word, i in word_index.items():\n",
    "#     try:\n",
    "#         embedding_vector = embeddings_index.get(word)\n",
    "#         embedding_matrix_glove[i] = embedding_vector\n",
    "#     except KeyError:\n",
    "#         embedding_matrix_glove[i]=np.random.normal(0,np.sqrt(0.25),embedDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "_ = glove2word2vec(glove_input_file='../../glove.840B.300d.txt', \n",
    "                   word2vec_output_file='../../gensim_glove_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 01:16:25.567910 140345287345984 utils_any2vec.py:185] duplicate word '����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������' in gensim_glove_vectors.txt, ignoring all but first\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('../../gensim_glove_vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_glove = np.zeros((vocabulary_size, embedDim))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix_glove[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix_glove[i]=np.random.normal(0,np.sqrt(0.25),embedDim)\n",
    "\n",
    "del(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.72040009e-01, -6.20299987e-02, -1.88400000e-01, ...,\n",
       "         1.30150005e-01, -1.83170006e-01,  1.32300004e-01],\n",
       "       [ 1.87329993e-01,  4.05950010e-01, -5.11740029e-01, ...,\n",
       "         1.64949998e-01,  1.87570006e-01,  5.38739979e-01],\n",
       "       ...,\n",
       "       [ 8.50461966e-01,  7.72688401e-01,  2.93645520e-01, ...,\n",
       "         2.66398705e-01,  7.22376178e-01, -5.67300393e-02],\n",
       "       [-5.57844013e-01,  8.07302036e-01,  5.37283119e-01, ...,\n",
       "        -1.99748411e-01, -4.28866949e-04, -4.69695892e-01],\n",
       "       [-4.09060001e-01,  1.50950000e-01,  9.60559994e-02, ...,\n",
       "         2.64380008e-01,  2.62639999e-01,  4.00190018e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_glove.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "\n",
    "def CreateKimCNN(kernelSize=[4, 5, 6], numFilters=128, embedDepth=300, \n",
    "                 dropOut=0.5, embeds=None, use=True, length=maxlen,\n",
    "                 vocab = vocabulary_size, pool = 2, denseInputs = 10):\n",
    "    \n",
    "    k1 = kernelSize[0]\n",
    "    k2 = kernelSize[1]\n",
    "    k3 = kernelSize[2]\n",
    "    \n",
    "    k1_inputs = Input(shape=(length,))\n",
    "    k2_inputs = Input(shape=(length,))\n",
    "    k3_inputs = Input(shape=(length,))\n",
    "       \n",
    "    if embeds == None:\n",
    "        k1_embeddings = Embedding(vocab, embedDepth)(k1_inputs)\n",
    "        k2_embeddings = Embedding(vocab, embedDepth)(k2_inputs)\n",
    "        k3_embeddings = Embedding(vocab, embedDepth)(k3_inputs)\n",
    "\n",
    "    elif embeds == 'w2v':\n",
    "        k1_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_w2v],\n",
    "                            trainable=True)(k1_inputs)\n",
    "        k2_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_w2v],\n",
    "                            trainable=True)(k2_inputs)\n",
    "        k3_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_w2v],\n",
    "                            trainable=True)(k3_inputs)\n",
    "        \n",
    "    elif embeds == 'Glove':\n",
    "        k1_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_glove],\n",
    "                            trainable=True)(k1_inputs)\n",
    "        k2_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_glove],\n",
    "                            trainable=True)(k2_inputs)\n",
    "        k3_embeddings = Embedding(vocabulary_size,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix_glove],\n",
    "                            trainable=True)(k3_inputs)\n",
    "    else:\n",
    "        print('Specify embeds correctly. Currently embeds =',embeds)\n",
    "        return\n",
    "    \n",
    "    k1_conv = Conv1D(filters=numFilters, kernel_size=k1, activation='relu')(k1_embeddings)\n",
    "    k1_dropout = Dropout(dropOut)(k1_conv)\n",
    "    k1_maxPool = MaxPooling1D(pool_size=pool)(k1_dropout)\n",
    "    k1_flatten = Flatten()(k1_maxPool)\n",
    "\n",
    "    k2_conv = Conv1D(filters=numFilters, kernel_size=k2, activation='relu')(k2_embeddings)\n",
    "    k2_dropout = Dropout(dropOut)(k2_conv)\n",
    "    k2_maxPool = MaxPooling1D(pool_size=pool)(k2_dropout)\n",
    "    k2_flatten = Flatten()(k2_maxPool)\n",
    "\n",
    "    k3_conv = Conv1D(filters=numFilters, kernel_size=k3, activation='relu')(k3_embeddings)\n",
    "    k3_dropout = Dropout(dropOut)(k3_conv)\n",
    "    k3_maxPool = MaxPooling1D(pool_size=pool)(k3_dropout)\n",
    "    k3_flatten = Flatten()(k3_maxPool)\n",
    "\n",
    "    if use == True:\n",
    "        use_inputs = Input(shape=(512,))\n",
    "        concat_kern = concatenate([k1_flatten, k2_flatten, k3_flatten, use_inputs])\n",
    "    else:\n",
    "        concat_kern = concatenate([k1_flatten, k2_flatten, k3_flatten])\n",
    "        \n",
    "    denseLayer = Dense(denseInputs, activation='relu')(concat_kern)\n",
    "    cnnOutputs = Dense(1, activation='sigmoid')(denseLayer)\n",
    "    \n",
    "    if use == True:\n",
    "        model = Model(inputs=[k1_inputs, k2_inputs, k3_inputs, use_inputs], outputs=cnnOutputs)\n",
    "    else:\n",
    "        model = Model(inputs=[k1_inputs, k2_inputs, k3_inputs], outputs=cnnOutputs)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "        \n",
    "    #plot_model(model, show_shapes=True, to_file='CNNModel.png')\n",
    "        \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 300, 300)     147300      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 300, 300)     147300      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 300, 300)     147300      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 297, 128)     153728      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 296, 128)     192128      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 295, 128)     230528      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 297, 128)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 296, 128)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 295, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 148, 128)     0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 148, 128)     0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 147, 128)     0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 18944)        0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 18944)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 18816)        0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 57216)        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           572170      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            11          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,590,465\n",
      "Trainable params: 1,590,465\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5112 - acc: 0.6000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1562 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0029 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9dfae5bf60>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embeds can be None, 'w2v', or 'Glove'\n",
    "#if use is True, you need to adjust the cnnModel.fit to include the USE outputs as an input\n",
    "\n",
    "# cnnModel = CreateKimCNN(kernelSize=[4, 5, 6], numFilters=128, embedDepth=300, \n",
    "#                  dropOut=0.5, embeds='Glove', use=False, length=maxlen,\n",
    "#                  vocab = vocabulary_size, pool = 2, denseInputs = 10)\n",
    "\n",
    "# cnnModel.fit([X_train,X_train,X_train], X_train_labels, epochs=10, batch_size=16)\n",
    "\n",
    "cnnModel = CreateKimCNN(kernelSize=[4, 5, 6], numFilters=128, embedDepth=300, \n",
    "                 dropOut=0.5, embeds='Glove', use=True, length=maxlen,\n",
    "                 vocab = vocabulary_size, pool = 2, denseInputs = 10)\n",
    "\n",
    "cnnModel.fit([X_train,X_train,X_train, review_embeddings], X_train_labels, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
